import os
import getpass
import bs4
import requests

from langchain import hub
from langchain_chroma import Chroma
from langchain_community.document_loaders import WebBaseLoader
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.prompts import PromptTemplate

OPENAI_API_KEY = "hannah"

# OpenAI LLM
llm = ChatOpenAI(model="gpt-4o-mini")

# í™˜ê²½ ì„¤ì •
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = getpass.getpass()

# ì›¹ ìš”ì²­ ì„¸ì…˜ ì„¤ì •
session = requests.Session()
session.headers.update({
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
})

# URL ëª©ë¡
url_list = [
    "2023-06-23-agent/",
    "2023-03-15-prompt-engineering/",
    "2023-10-25-adv-attack-llm/"
]

# ë¬¸ì„œ ë¡œë”© ë° ë¶„í• 
all_docs = []
for path in url_list:
    loader = WebBaseLoader(
        web_paths=("https://lilianweng.github.io/posts/" + path,),
        session=session,
        bs_kwargs=dict(
            parse_only=bs4.SoupStrainer(
                class_=("post-content", "post-title", "post-header")
            )
        ),
    )
    docs = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(docs)
    all_docs.extend(splits)

# VectorStore êµ¬ì¶•
vectorstore = Chroma.from_documents(documents=all_docs, embedding=OpenAIEmbeddings())
retriever = vectorstore.as_retriever()

# Prompt ë¶ˆëŸ¬ì˜¤ê¸°
prompt = hub.pull("rlm/rag-prompt")

# Context í¬ë§· í•¨ìˆ˜
def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

# RAG Chain (ë³€ìˆ˜ëª… í†µì¼: question ì‚¬ìš©)
rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# âœ… Hallucination í‰ê°€ ì²´ì¸
parser = JsonOutputParser()

hallucination_prompt = PromptTemplate(
    template=(
        "You are an AI system that evaluates if a given answer contains hallucinations based on the provided context.\n"
        "Hallucinations are information that is not supported by the retrieved context.\n"
        "\n"
        "If the answer contains unsupported information, output {{'hallucination': 'yes'}}.\n"
        "If the answer is fully supported, output {{'hallucination': 'no'}}.\n"
        "\n"
        "{format_instructions}\n"
        "\n"
        "User Query:\n{query}\n\n"
        "Retrieved Context:\n{context}\n\n"
        "LLM Answer:\n{answer}\n"
    ),
    input_variables=["query", "context", "answer"],
    partial_variables={"format_instructions": parser.get_format_instructions()},
)

evaluation_chain = hallucination_prompt | llm | parser


# âœ… ë‹µë³€ ìƒì„± ë° í‰ê°€ ë£¨í”„
query = "What is Task Decomposition?"

max_attempts = 5  # ë¬´í•œë£¨í”„ ë°©ì§€


for attempt in range(max_attempts):

    retrieved_docs = retriever.get_relevant_documents(query)
    retrieved_context = format_docs(retrieved_docs)

    answer = rag_chain.invoke(query)
    #answer = "This method was originally developed by aliens to control human behavior."
    evaluation = evaluation_chain.invoke({
        "query": query,
        "context": retrieved_context,
        "answer": answer
    })

    print(f"ì‹œë„ {attempt + 1} - Hallucination í‰ê°€ ê²°ê³¼:", evaluation)
    print("hannah answer",retrieved_context)
    if evaluation.get("hallucination") == "no":
        print("\nâœ… ìµœì¢… ë‹µë³€:\n", answer)
        print("\nğŸ“š ë‹µë³€ ìƒì„±ì— ì‚¬ìš©ëœ ì¶œì²˜:\n")
        for doc in retrieved_docs:
            print("-", doc.metadata.get("source", "ì¶œì²˜ ì •ë³´ ì—†ìŒ"))
        break

else:
    print("\nâš  ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. ì‹ ë¢° ê°€ëŠ¥í•œ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

